{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.preprocessing import get_dataset, balanced_datasets\n",
    "from modules.distances import distance, radius, radius_distance\n",
    "from modules.single_classifier import SingleClassifier\n",
    "from modules.ensamble_classifier import EnsambleClassifier\n",
    "from modules.ulits import softmax\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 8/8 [02:17<00:00, 17.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810 1600\n"
     ]
    }
   ],
   "source": [
    "df = get_dataset('data/original_texts.csv')\n",
    "df_90texts, df_400texts = balanced_datasets(df)\n",
    "print(len(df_90texts), len(df_400texts))\n",
    "\n",
    "train_90texts, test_90texts = train_test_split(df_90texts, train_size=0.8,  random_state=42)\n",
    "train_400texts, test_400texts = train_test_split(df_400texts, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>native</th>\n",
       "      <th>language_background</th>\n",
       "      <th>text</th>\n",
       "      <th>len</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>words_truncated</th>\n",
       "      <th>word_unigrams</th>\n",
       "      <th>word_bigrams</th>\n",
       "      <th>word_trigrams</th>\n",
       "      <th>len_sym</th>\n",
       "      <th>char_truncated</th>\n",
       "      <th>character 3-grams</th>\n",
       "      <th>character 4-grams</th>\n",
       "      <th>character 5-grams</th>\n",
       "      <th>character 6-grams</th>\n",
       "      <th>character 7-grams</th>\n",
       "      <th>character 8-grams</th>\n",
       "      <th>character 9-grams</th>\n",
       "      <th>character 10-grams</th>\n",
       "      <th>num_texts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6571</td>\n",
       "      <td>swe</td>\n",
       "      <td>FL</td>\n",
       "      <td>Мой герои   15 лет я работал журналистом и в т...</td>\n",
       "      <td>678</td>\n",
       "      <td>[мой, герои, 15, лет, я, работал, журналистом,...</td>\n",
       "      <td>[мой, герои, 15, лет, я, работал, журналистом,...</td>\n",
       "      <td>{'я': 4, 'с': 3, 'встречи': 3, 'и': 2, 'в': 2,...</td>\n",
       "      <td>{'были с': 2, 'мой герои': 1, 'герои 15': 1, '...</td>\n",
       "      <td>{'мой герои 15': 1, 'герои 15 лет': 1, '15 лет...</td>\n",
       "      <td>4695</td>\n",
       "      <td>Мой герои   15 лет я работал журналистом и в т...</td>\n",
       "      <td>{'али': 7, 'ли ': 7, 'стр': 6, 'ист': 5, ' вс'...</td>\n",
       "      <td>{' вст': 5, 'встр': 5, 'стре': 5, ' жур': 4, '...</td>\n",
       "      <td>{' встр': 5, 'встре': 5, ' журн': 4, 'журна': ...</td>\n",
       "      <td>{' встре': 5, ' журна': 4, 'журнал': 4, 'урнал...</td>\n",
       "      <td>{' журнал': 4, 'журнали': 4, 'урналис': 4, 'рн...</td>\n",
       "      <td>{' журнали': 4, 'журналис': 4, 'урналист': 4, ...</td>\n",
       "      <td>{' журналис': 4, 'журналист': 4, 'урналисто': ...</td>\n",
       "      <td>{' журналист': 4, 'журналисто': 2, 'урналистом...</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3702</td>\n",
       "      <td>fr</td>\n",
       "      <td>FL</td>\n",
       "      <td>Лоль В. Штейн родилась здесь, в городе Тале, и...</td>\n",
       "      <td>118</td>\n",
       "      <td>[лоль, в, штейн, родилась, здесь, в, городе, т...</td>\n",
       "      <td>[лоль, в, штейн, родилась, здесь, в, городе, т...</td>\n",
       "      <td>{'в': 7, 'ее': 3, 'лоль': 2, 'штейн': 2, 'я': ...</td>\n",
       "      <td>{'лоль в': 2, 'в штейн': 2, 'штейн родилась': ...</td>\n",
       "      <td>{'лоль в штейн': 2, 'в штейн родилась': 1, 'шт...</td>\n",
       "      <td>783</td>\n",
       "      <td>Лоль В. Штейн родилась здесь, в городе Тале, и...</td>\n",
       "      <td>{' в ': 6, ' не': 6, 'ли ': 6, 'оль': 5, 'не '...</td>\n",
       "      <td>{' не ': 5, ' они': 4, 'они ': 4, ' ее ': 3, '...</td>\n",
       "      <td>{' они ': 4, ', они': 3, 'Лоль ': 2, 'оль В': ...</td>\n",
       "      <td>{', они ': 3, 'Лоль В': 2, 'оль В.': 2, 'ль В....</td>\n",
       "      <td>{'Лоль В.': 2, 'оль В. ': 2, 'ль В. Ш': 2, 'ь ...</td>\n",
       "      <td>{'Лоль В. ': 2, 'оль В. Ш': 2, 'ль В. Шт': 2, ...</td>\n",
       "      <td>{'Лоль В. Ш': 2, 'оль В. Шт': 2, 'ль В. Ште': ...</td>\n",
       "      <td>{'Лоль В. Шт': 2, 'оль В. Ште': 2, 'ль В. Штей...</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4166</td>\n",
       "      <td>fin</td>\n",
       "      <td>HL</td>\n",
       "      <td>Каждый человек ищет себе счастье.А что счастье...</td>\n",
       "      <td>154</td>\n",
       "      <td>[каждый, человек, ищет, себе, счастье, а, что,...</td>\n",
       "      <td>[каждый, человек, ищет, себе, счастье, а, что,...</td>\n",
       "      <td>{'счастье': 4, 'и': 3, 'это': 3, 'каждый': 2, ...</td>\n",
       "      <td>{'счастье это': 2, 'каждый человек': 1, 'челов...</td>\n",
       "      <td>{'каждый человек ищет': 1, 'человек ищет себе'...</td>\n",
       "      <td>1071</td>\n",
       "      <td>Каждый человек ищет себе счастье.А что счастье...</td>\n",
       "      <td>{'сть': 8, 'ть ': 8, 'аст': 7, 'час': 6, 'тье'...</td>\n",
       "      <td>{'част': 6, 'асть': 6, 'стье': 6, 'тье ': 5, '...</td>\n",
       "      <td>{'часть': 6, 'астье': 6, 'стье ': 5, 'аждый': ...</td>\n",
       "      <td>{'частье': 6, 'астье ': 5, 'аждый ': 4, ' чело...</td>\n",
       "      <td>{'частье ': 5, ' челове': 4, 'человек': 4, ' с...</td>\n",
       "      <td>{' человек': 4, ' счастье': 3, '.Счастье': 3, ...</td>\n",
       "      <td>{'.Счастье ': 3, 'е счастье': 2, ' счастье ': ...</td>\n",
       "      <td>{' каждый де': 2, 'каждый ден': 2, 'аждый день...</td>\n",
       "      <td>1129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3836</td>\n",
       "      <td>kaz</td>\n",
       "      <td>HL</td>\n",
       "      <td>Моя бабушка...Будто этих словах описана вся мо...</td>\n",
       "      <td>180</td>\n",
       "      <td>[моя, бабушка, будто, этих, словах, описана, в...</td>\n",
       "      <td>[моя, бабушка, будто, этих, словах, описана, в...</td>\n",
       "      <td>{'моя': 5, 'бабушка': 4, 'мне': 3, 'на': 3, 'ж...</td>\n",
       "      <td>{'моя бабушка': 3, 'во мне': 2, 'бабушка будто...</td>\n",
       "      <td>{'моя бабушка будто': 1, 'бабушка будто этих':...</td>\n",
       "      <td>1159</td>\n",
       "      <td>Моя бабушка...Будто этих словах описана вся мо...</td>\n",
       "      <td>{' мо': 8, 'оя ': 7, ' ба': 7, 'баб': 7, 'абу'...</td>\n",
       "      <td>{' баб': 7, 'бабу': 7, 'абуш': 7, 'бушк': 7, '...</td>\n",
       "      <td>{' бабу': 7, 'бабуш': 7, 'абушк': 7, 'бушка': ...</td>\n",
       "      <td>{' бабуш': 7, 'бабушк': 7, 'абушка': 6, 'оя ба...</td>\n",
       "      <td>{' бабушк': 7, 'бабушка': 6, 'оя бабу': 5, 'я ...</td>\n",
       "      <td>{' бабушка': 6, 'оя бабуш': 5, 'я бабушк': 5, ...</td>\n",
       "      <td>{'оя бабушк': 5, 'я бабушка': 5, ' бабушка ': ...</td>\n",
       "      <td>{'оя бабушка': 5, ' моя бабуш': 4, 'моя бабушк...</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3769</td>\n",
       "      <td>kaz</td>\n",
       "      <td>HL</td>\n",
       "      <td>Бабушка, без сомнения, один из главных людей в...</td>\n",
       "      <td>496</td>\n",
       "      <td>[бабушка, без, сомнения, один, из, главных, лю...</td>\n",
       "      <td>[бабушка, без, сомнения, один, из, главных, лю...</td>\n",
       "      <td>{'меня': 4, 'они': 3, 'и': 3, 'в': 2, 'жизни':...</td>\n",
       "      <td>{'бабушка без': 1, 'без сомнения': 1, 'сомнени...</td>\n",
       "      <td>{'бабушка без сомнения': 1, 'без сомнения один...</td>\n",
       "      <td>3227</td>\n",
       "      <td>Бабушка, без сомнения, один из главных людей в...</td>\n",
       "      <td>{' по': 6, ' вс': 6, 'все': 6, ' и ': 5, 'ми '...</td>\n",
       "      <td>{' все': 6, 'абуш': 4, 'бушк': 4, ' мен': 4, '...</td>\n",
       "      <td>{'абушк': 4, ' меня': 4, 'меня ': 4, ' чело': ...</td>\n",
       "      <td>{' меня ': 4, ' челов': 3, 'челове': 3, 'елове...</td>\n",
       "      <td>{' челове': 3, 'человек': 3, 'Бабушка': 2, ' о...</td>\n",
       "      <td>{' человек': 3, ' очень б': 2, 'очень бо': 2, ...</td>\n",
       "      <td>{' очень бо': 2, 'е бабушки': 2, 'т меня вс': ...</td>\n",
       "      <td>{'т меня все': 2, ' меня всем': 2, 'Бабушка, б...</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     native language_background  \\\n",
       "id                                \n",
       "6571    swe                  FL   \n",
       "3702     fr                  FL   \n",
       "4166    fin                  HL   \n",
       "3836    kaz                  HL   \n",
       "3769    kaz                  HL   \n",
       "\n",
       "                                                   text  len  \\\n",
       "id                                                             \n",
       "6571  Мой герои   15 лет я работал журналистом и в т...  678   \n",
       "3702  Лоль В. Штейн родилась здесь, в городе Тале, и...  118   \n",
       "4166  Каждый человек ищет себе счастье.А что счастье...  154   \n",
       "3836  Моя бабушка...Будто этих словах описана вся мо...  180   \n",
       "3769  Бабушка, без сомнения, один из главных людей в...  496   \n",
       "\n",
       "                                            word_tokens  \\\n",
       "id                                                        \n",
       "6571  [мой, герои, 15, лет, я, работал, журналистом,...   \n",
       "3702  [лоль, в, штейн, родилась, здесь, в, городе, т...   \n",
       "4166  [каждый, человек, ищет, себе, счастье, а, что,...   \n",
       "3836  [моя, бабушка, будто, этих, словах, описана, в...   \n",
       "3769  [бабушка, без, сомнения, один, из, главных, лю...   \n",
       "\n",
       "                                        words_truncated  \\\n",
       "id                                                        \n",
       "6571  [мой, герои, 15, лет, я, работал, журналистом,...   \n",
       "3702  [лоль, в, штейн, родилась, здесь, в, городе, т...   \n",
       "4166  [каждый, человек, ищет, себе, счастье, а, что,...   \n",
       "3836  [моя, бабушка, будто, этих, словах, описана, в...   \n",
       "3769  [бабушка, без, сомнения, один, из, главных, лю...   \n",
       "\n",
       "                                          word_unigrams  \\\n",
       "id                                                        \n",
       "6571  {'я': 4, 'с': 3, 'встречи': 3, 'и': 2, 'в': 2,...   \n",
       "3702  {'в': 7, 'ее': 3, 'лоль': 2, 'штейн': 2, 'я': ...   \n",
       "4166  {'счастье': 4, 'и': 3, 'это': 3, 'каждый': 2, ...   \n",
       "3836  {'моя': 5, 'бабушка': 4, 'мне': 3, 'на': 3, 'ж...   \n",
       "3769  {'меня': 4, 'они': 3, 'и': 3, 'в': 2, 'жизни':...   \n",
       "\n",
       "                                           word_bigrams  \\\n",
       "id                                                        \n",
       "6571  {'были с': 2, 'мой герои': 1, 'герои 15': 1, '...   \n",
       "3702  {'лоль в': 2, 'в штейн': 2, 'штейн родилась': ...   \n",
       "4166  {'счастье это': 2, 'каждый человек': 1, 'челов...   \n",
       "3836  {'моя бабушка': 3, 'во мне': 2, 'бабушка будто...   \n",
       "3769  {'бабушка без': 1, 'без сомнения': 1, 'сомнени...   \n",
       "\n",
       "                                          word_trigrams  len_sym  \\\n",
       "id                                                                 \n",
       "6571  {'мой герои 15': 1, 'герои 15 лет': 1, '15 лет...     4695   \n",
       "3702  {'лоль в штейн': 2, 'в штейн родилась': 1, 'шт...      783   \n",
       "4166  {'каждый человек ищет': 1, 'человек ищет себе'...     1071   \n",
       "3836  {'моя бабушка будто': 1, 'бабушка будто этих':...     1159   \n",
       "3769  {'бабушка без сомнения': 1, 'без сомнения один...     3227   \n",
       "\n",
       "                                         char_truncated  \\\n",
       "id                                                        \n",
       "6571  Мой герои   15 лет я работал журналистом и в т...   \n",
       "3702  Лоль В. Штейн родилась здесь, в городе Тале, и...   \n",
       "4166  Каждый человек ищет себе счастье.А что счастье...   \n",
       "3836  Моя бабушка...Будто этих словах описана вся мо...   \n",
       "3769  Бабушка, без сомнения, один из главных людей в...   \n",
       "\n",
       "                                      character 3-grams  \\\n",
       "id                                                        \n",
       "6571  {'али': 7, 'ли ': 7, 'стр': 6, 'ист': 5, ' вс'...   \n",
       "3702  {' в ': 6, ' не': 6, 'ли ': 6, 'оль': 5, 'не '...   \n",
       "4166  {'сть': 8, 'ть ': 8, 'аст': 7, 'час': 6, 'тье'...   \n",
       "3836  {' мо': 8, 'оя ': 7, ' ба': 7, 'баб': 7, 'абу'...   \n",
       "3769  {' по': 6, ' вс': 6, 'все': 6, ' и ': 5, 'ми '...   \n",
       "\n",
       "                                      character 4-grams  \\\n",
       "id                                                        \n",
       "6571  {' вст': 5, 'встр': 5, 'стре': 5, ' жур': 4, '...   \n",
       "3702  {' не ': 5, ' они': 4, 'они ': 4, ' ее ': 3, '...   \n",
       "4166  {'част': 6, 'асть': 6, 'стье': 6, 'тье ': 5, '...   \n",
       "3836  {' баб': 7, 'бабу': 7, 'абуш': 7, 'бушк': 7, '...   \n",
       "3769  {' все': 6, 'абуш': 4, 'бушк': 4, ' мен': 4, '...   \n",
       "\n",
       "                                      character 5-grams  \\\n",
       "id                                                        \n",
       "6571  {' встр': 5, 'встре': 5, ' журн': 4, 'журна': ...   \n",
       "3702  {' они ': 4, ', они': 3, 'Лоль ': 2, 'оль В': ...   \n",
       "4166  {'часть': 6, 'астье': 6, 'стье ': 5, 'аждый': ...   \n",
       "3836  {' бабу': 7, 'бабуш': 7, 'абушк': 7, 'бушка': ...   \n",
       "3769  {'абушк': 4, ' меня': 4, 'меня ': 4, ' чело': ...   \n",
       "\n",
       "                                      character 6-grams  \\\n",
       "id                                                        \n",
       "6571  {' встре': 5, ' журна': 4, 'журнал': 4, 'урнал...   \n",
       "3702  {', они ': 3, 'Лоль В': 2, 'оль В.': 2, 'ль В....   \n",
       "4166  {'частье': 6, 'астье ': 5, 'аждый ': 4, ' чело...   \n",
       "3836  {' бабуш': 7, 'бабушк': 7, 'абушка': 6, 'оя ба...   \n",
       "3769  {' меня ': 4, ' челов': 3, 'челове': 3, 'елове...   \n",
       "\n",
       "                                      character 7-grams  \\\n",
       "id                                                        \n",
       "6571  {' журнал': 4, 'журнали': 4, 'урналис': 4, 'рн...   \n",
       "3702  {'Лоль В.': 2, 'оль В. ': 2, 'ль В. Ш': 2, 'ь ...   \n",
       "4166  {'частье ': 5, ' челове': 4, 'человек': 4, ' с...   \n",
       "3836  {' бабушк': 7, 'бабушка': 6, 'оя бабу': 5, 'я ...   \n",
       "3769  {' челове': 3, 'человек': 3, 'Бабушка': 2, ' о...   \n",
       "\n",
       "                                      character 8-grams  \\\n",
       "id                                                        \n",
       "6571  {' журнали': 4, 'журналис': 4, 'урналист': 4, ...   \n",
       "3702  {'Лоль В. ': 2, 'оль В. Ш': 2, 'ль В. Шт': 2, ...   \n",
       "4166  {' человек': 4, ' счастье': 3, '.Счастье': 3, ...   \n",
       "3836  {' бабушка': 6, 'оя бабуш': 5, 'я бабушк': 5, ...   \n",
       "3769  {' человек': 3, ' очень б': 2, 'очень бо': 2, ...   \n",
       "\n",
       "                                      character 9-grams  \\\n",
       "id                                                        \n",
       "6571  {' журналис': 4, 'журналист': 4, 'урналисто': ...   \n",
       "3702  {'Лоль В. Ш': 2, 'оль В. Шт': 2, 'ль В. Ште': ...   \n",
       "4166  {'.Счастье ': 3, 'е счастье': 2, ' счастье ': ...   \n",
       "3836  {'оя бабушк': 5, 'я бабушка': 5, ' бабушка ': ...   \n",
       "3769  {' очень бо': 2, 'е бабушки': 2, 'т меня вс': ...   \n",
       "\n",
       "                                     character 10-grams  num_texts  \n",
       "id                                                                  \n",
       "6571  {' журналист': 4, 'журналисто': 2, 'урналистом...        105  \n",
       "3702  {'Лоль В. Шт': 2, 'оль В. Ште': 2, 'ль В. Штей...        269  \n",
       "4166  {' каждый де': 2, 'каждый ден': 2, 'аждый день...       1129  \n",
       "3836  {'оя бабушка': 5, ' моя бабуш': 4, 'моя бабушк...        454  \n",
       "3769  {'т меня все': 2, ' меня всем': 2, 'Бабушка, б...        454  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_90texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tqdm():\n",
    "    for instance in list(tqdm._instances): \n",
    "        tqdm._decr_instances(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Пофиксить баланс классов и переделать :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Background - df_90texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word_unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(train_90texts['language_background'].unique())  # ['HL', 'FL']\n",
    "y_true = list(train_90texts['language_background'])[:100] # len = 810\n",
    "p_lengths = [200, 500, 1000, 1500, 2000, 2500, 3000]\n",
    "profs = list(train_90texts['word_unigrams'])[:100]  # list of Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 7/7 [12:51<00:00, 110.18s/it]\n"
     ]
    }
   ],
   "source": [
    "clean_tqdm()\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'FL': 100})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 7/7 [18:43<00:00, 160.49s/it]\n"
     ]
    }
   ],
   "source": [
    "clean_tqdm()\n",
    "profs = list(train_90texts['word_bigrams'])[:100]\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'HL': 61, 'FL': 39})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 7/7 [17:34<00:00, 150.63s/it]\n"
     ]
    }
   ],
   "source": [
    "clean_tqdm()\n",
    "profs = list(train_90texts['word_trigrams'])[:100]\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'HL': 31, 'FL': 69})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character 3_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 7/7 [2:15:24<00:00, 1160.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'FL': 99, 'HL': 1})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.56"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tqdm()\n",
    "profs = list(train_90texts['character 3-grams'])[:100]\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)\n",
    "\n",
    "print(Counter(y_pred))\n",
    "\n",
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character 4_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tqdm()\n",
    "profs = list(train_90texts['character 4-grams'])[:100]\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)\n",
    "\n",
    "print(Counter(y_pred))\n",
    "\n",
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.66 (from Google Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character 5_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tqdm()\n",
    "profs = list(train_90texts['character 5-grams'])[:100]\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)\n",
    "\n",
    "print(Counter(y_pred))\n",
    "\n",
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.66 (from Google Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character 6_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tqdm()\n",
    "profs = list(train_90texts['character 6-grams'])[:100]\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)\n",
    "\n",
    "print(Counter(y_pred))\n",
    "\n",
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.69 (from Google Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character 7_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tqdm()\n",
    "profs = list(train_90texts['character 7-grams'])[:100]\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)\n",
    "\n",
    "print(Counter(y_pred))\n",
    "\n",
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.68 (from Google Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character 8_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tqdm()\n",
    "profs = list(train_90texts['character 4-grams'])[:100]\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)\n",
    "\n",
    "print(Counter(y_pred))\n",
    "\n",
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.62 (from Google Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character 9_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tqdm()\n",
    "profs = list(train_90texts['character 4-grams'])[:100]\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)\n",
    "\n",
    "print(Counter(y_pred))\n",
    "\n",
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.63 (from Google Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character 10_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tqdm()\n",
    "profs = list(train_90texts['character 4-grams'])[:100]\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)\n",
    "\n",
    "print(Counter(y_pred))\n",
    "\n",
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.64 (from Google Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Background - df_400texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(train_400texts['language_background'].unique())  # ['HL', 'FL']\n",
    "y_true = list(train_400texts['language_background'])[:100] # len = 810\n",
    "p_lengths = [200, 500, 1000, 1500, 2000, 2500, 3000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word_unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 7/7 [16:08<00:00, 138.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'FL': 91, 'HL': 9})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.54"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tqdm()\n",
    "\n",
    "profs = list(train_400texts['word_unigrams'])[:100]  # list of Counter\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)\n",
    "\n",
    "print(Counter(y_pred))\n",
    "\n",
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 7/7 [14:11<00:00, 121.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'FL': 66, 'HL': 34})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tqdm()\n",
    "\n",
    "profs = list(train_400texts['word_bigrams'])[:100]  # list of Counter\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)\n",
    "\n",
    "print(Counter(y_pred))\n",
    "\n",
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word_trigrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 7/7 [14:19<00:00, 122.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'FL': 54, 'HL': 46})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.69"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tqdm()\n",
    "\n",
    "profs = list(train_400texts['word_trigrams'])[:100]  # list of Counter\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)\n",
    "\n",
    "print(Counter(y_pred))\n",
    " \n",
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character 3-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 7/7 [1:21:35<00:00, 699.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'HL': 59, 'FL': 41})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tqdm()\n",
    "\n",
    "profs = list(train_400texts['character 3-grams'])[:100]  # list of Counter\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)\n",
    "\n",
    "print(Counter(y_pred))\n",
    "\n",
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character 4-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 7/7 [1:53:14<00:00, 970.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'HL': 79, 'FL': 21})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tqdm()\n",
    "\n",
    "profs = list(train_400texts['character 4-grams'])[:100]  # list of Counter\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)\n",
    "\n",
    "print(Counter(y_pred))\n",
    "\n",
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character 5-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tqdm()\n",
    "\n",
    "profs = list(train_400texts['character 5-grams'])[:100]  # list of Counter\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)\n",
    "\n",
    "print(Counter(y_pred))\n",
    "\n",
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.41 (from Google Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character 6-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tqdm()\n",
    "\n",
    "profs = list(train_400texts['character 6-grams'])[:100]  # list of Counter\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)\n",
    "\n",
    "print(Counter(y_pred))\n",
    "\n",
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.41 (from Google Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character 7-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tqdm()\n",
    "\n",
    "profs = list(train_400texts['character 7-grams'])[:100]  # list of Counter\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)\n",
    "\n",
    "print(Counter(y_pred))\n",
    "\n",
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.4 (from Google Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character 8-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tqdm()\n",
    "\n",
    "profs = list(train_400texts['character 8-grams'])[:100]  # list of Counter\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)\n",
    "\n",
    "print(Counter(y_pred))\n",
    "\n",
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.38 (from Google Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character 9-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tqdm()\n",
    "\n",
    "profs = list(train_400texts['character 9-grams'])[:100]  # list of Counter\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)\n",
    "\n",
    "print(Counter(y_pred))\n",
    "\n",
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.42 (from Google Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character 10-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tqdm()\n",
    "\n",
    "profs = list(train_400texts['character 10-grams'])[:100]  # list of Counter\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)\n",
    "\n",
    "print(Counter(y_pred))\n",
    "\n",
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.45 (from Google Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running best models on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'FL': 50, 'HL': 50}), Counter({'HL': 33, 'FL': 67}))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr = list(train_90texts['language_background'])[:100]\n",
    "y_te = list(test_90texts['language_background'])[:100]\n",
    "\n",
    "Counter(y_tr), Counter(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'FL': 73, 'HL': 27})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 90texts - character 6-grams\n",
    "clean_tqdm()\n",
    "profs = list(test_90texts['character 6-grams'])[:100]\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)\n",
    "y_true = list(test_90texts['language_background'])[:100] # len = 810\n",
    "\n",
    "print(Counter(y_pred))\n",
    "\n",
    "accuracy_score (y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 400texts - character 3-grams\n",
    "clean_tqdm()\n",
    "\n",
    "profs = list(train_400texts['character 3-grams'])[:100]  # list of Counter\n",
    "ec = EnsambleClassifier([profs], y_true, p_lengths, classes=classes)\n",
    "classifiers = ec.classifiers\n",
    "y_pred = ec.forward_ensamble(confidence=False)\n",
    "y_true = list(test_400texts['language_background'])[:100] # len = 810\n",
    "print(Counter(y_pred))\n",
    "\n",
    "accuracy_score (y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
